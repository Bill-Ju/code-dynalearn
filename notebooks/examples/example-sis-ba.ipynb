{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of dynamics learning of SIS on BA networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show an example of dynamics learning of SIS dynamics on Barabasi-Albert networks. We first start by gathering the configuration of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynalearn.config import ExperimentConfig\n",
    "\n",
    "config = ExperimentConfig.default(\n",
    "    \"example-sis-ba\", \n",
    "    \"sis\", \n",
    "    \"ba\", \n",
    "    path_to_data=\"./examples/data\", \n",
    "    path_to_summary=\"./examples/summaries\", \n",
    "    path_to_best=\"./examples/best\", \n",
    "    seed=0\n",
    ")\n",
    "config.metrics.names = (\"TrueLTPMetrics\",\"GNNLTPMetrics\",\"MLELTPMetrics\")\n",
    "config.train_details.num_samples = 1000\n",
    "config.train_details.epochs = 10\n",
    "config.train_details.use_groundtruth = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the experiment from this configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynalearn.experiments import Experiment\n",
    "exp = Experiment(config, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run the experiment. We must perform certain tasks before the experiment is completed: 1) we generate the training and validation datasets, 2) we train the model using these datasets and finally 3) we compute the transition probabilities computed by the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Experiment example-sis-ba---\n",
      "Current time: 2021-05-27 14:07:05\n",
      "\n",
      "---Config---\n",
      "name: example-sis-ba\n",
      "path_to_data: ./examples/data/example-sis-ba\n",
      "path_to_best: ./examples/best/example-sis-ba.pt\n",
      "path_to_summary: ./examples/summaries\n",
      "dynamics:\n",
      "\tname: SIS\n",
      "\tinfection: 0.04\n",
      "\trecovery: 0.08\n",
      "\tinit_param: None\n",
      "\tis_weighted: False\n",
      "\tis_multiplex: False\n",
      "\tlag: 1\n",
      "\tlagstep: 1\n",
      "\n",
      "networks:\n",
      "\tname: BANetworkGenerator\n",
      "\tnum_nodes: 1000\n",
      "\tm: 2\n",
      "\n",
      "model:\n",
      "\tname: GNNSEDynamics\n",
      "\tgnn_name: DynamicsGATConv\n",
      "\ttype: linear\n",
      "\tnum_states: 2\n",
      "\toptimizer:\n",
      "\t\tname: RAdam\n",
      "\t\tlr: 0.001\n",
      "\t\tweight_decay: 0.0001\n",
      "\t\tbetas: (0.9, 0.999)\n",
      "\t\teps: 1e-08\n",
      "\t\tamsgrad: False\n",
      "\n",
      "\tin_activation: relu\n",
      "\tgnn_activation: relu\n",
      "\tout_activation: relu\n",
      "\tin_channels: [32, 32]\n",
      "\tgnn_channels: 32\n",
      "\tout_channels: [32, 32]\n",
      "\theads: 2\n",
      "\tconcat: True\n",
      "\tbias: True\n",
      "\tself_attention: True\n",
      "\tis_weighted: False\n",
      "\tis_multiplex: False\n",
      "\tnetwork_layers: None\n",
      "\tin_size: 1\n",
      "\tout_size: 2\n",
      "\tout_act: softmax\n",
      "\tnode_channels: [0]\n",
      "\tnum_params: 8810\n",
      "\tlag: 1\n",
      "\tlagstep: 1\n",
      "\n",
      "dataset:\n",
      "\tname: DiscreteStateWeightDataset\n",
      "\tmodes: ['main']\n",
      "\tbias: 0\n",
      "\treplace: True\n",
      "\tuse_groundtruth: False\n",
      "\tuse_strength: True\n",
      "\tcompounded: True\n",
      "\n",
      "train_details:\n",
      "\tval_fraction: 0.01\n",
      "\tval_bias: 0.8\n",
      "\tepochs: 10\n",
      "\tbatch_size: 1\n",
      "\tnum_networks: 1\n",
      "\tnum_samples: 1000\n",
      "\tresampling: 2\n",
      "\tmaxlag: 1\n",
      "\tresample_when_dead: True\n",
      "\tuse_groundtruth: 1\n",
      "\n",
      "metrics:\n",
      "\tnames: ('TrueLTPMetrics', 'GNNLTPMetrics', 'MLELTPMetrics')\n",
      "\tltp:\n",
      "\t\tmax_num_sample: 1000\n",
      "\t\tmax_num_points: -1\n",
      "\n",
      "\tprediciton:\n",
      "\t\tmax_num_points: 10000.0\n",
      "\n",
      "\tstatistics:\n",
      "\t\tmax_num_points: 10000\n",
      "\t\tmaxlag: 1\n",
      "\n",
      "\tstationary:\n",
      "\t\tadaptive: True\n",
      "\t\tnum_nodes: 1000\n",
      "\t\tinit_param: {'absorbing': array([0.999, 0.001])}\n",
      "\t\tsampler: SteadyStateSampler\n",
      "\t\tburn: 1\n",
      "\t\tT: 1000\n",
      "\t\ttol: 500\n",
      "\t\tnum_samples: 5\n",
      "\t\tstatistics: MeanVarStatistics\n",
      "\t\tinit_epsilon: 0.001\n",
      "\t\tparameters: {'absorbing': array([0.1       , 0.24081633, 0.38163265, 0.52244898, 0.66326531,\n",
      "       0.80408163, 0.94489796, 1.08571429, 1.22653061, 1.36734694,\n",
      "       1.50816327, 1.64897959, 1.78979592, 1.93061224, 2.07142857,\n",
      "       2.2122449 , 2.35306122, 2.49387755, 2.63469388, 2.7755102 ,\n",
      "       2.91632653, 3.05714286, 3.19795918, 3.33877551, 3.47959184,\n",
      "       3.62040816, 3.76122449, 3.90204082, 4.04285714, 4.18367347,\n",
      "       4.3244898 , 4.46530612, 4.60612245, 4.74693878, 4.8877551 ,\n",
      "       5.02857143, 5.16938776, 5.31020408, 5.45102041, 5.59183673,\n",
      "       5.73265306, 5.87346939, 6.01428571, 6.15510204, 6.29591837,\n",
      "       6.43673469, 6.57755102, 6.71836735, 6.85918367, 7.        ])}\n",
      "\n",
      "\tattention:\n",
      "\t\tmax_num_points: 100\n",
      "\n",
      "\n",
      "train_metrics: ['jensenshannon', 'model_entropy']\n",
      "callbacks:\n",
      "\tnames: ['ModelCheckpoint', 'StepLR']\n",
      "\tstep_size: 20\n",
      "\tgamma: 0.5\n",
      "\tpath_to_best: ./examples/best/example-sis-ba.pt\n",
      "\n",
      "seed: 0\n",
      "\n",
      "\n",
      "---Generating data---\n",
      "Generating training set\n",
      "Computing weights\n"
     ]
    }
   ],
   "source": [
    "exp.run([\"generate_data\", \"partition_val_dataset\", \"train_model\", \"compute_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.set_context(\"notebook\")\n",
    "\n",
    "def plot_ltp(experiment, ax):\n",
    "    summary = experiment.metrics[\"TrueLTPMetrics\"].data[\"summaries\"]\n",
    "    true_ltp = experiment.metrics[\"TrueLTPMetrics\"].data[\"ltp\"]\n",
    "    gnn_ltp = experiment.metrics[\"GNNLTPMetrics\"].data[\"ltp\"]\n",
    "    mle_ltp = experiment.metrics[\"MLELTPMetrics\"].data[\"ltp\"]\n",
    "    agg = lambda ltp, in_s, out_s: LTPMetrics.aggregate(\n",
    "            ltp, summary, \n",
    "            in_state=in_s, \n",
    "            out_state=out_s,\n",
    "            axis=1, \n",
    "            reduce=\"mean\", \n",
    "            err_reduce=\"percentile\"\n",
    "        )\n",
    "    x_min, x_max = -np.inf, np.inf\n",
    "    for i, (in_s, out_s) in enumerate(transitions):\n",
    "        x, y, yl, yh = agg(true_ltp, in_s, out_s)\n",
    "        ax.plot(\n",
    "            x, y, color=colors[\"true\"][i], linestyle=linestyles[\"true\"][i],marker=markers[\"true\"][i],linewidth=3\n",
    "        )\n",
    "        ax.fill_between(x, yl, yh, color=colors[\"true\"][i], alpha=0.3)\n",
    "        \n",
    "        x, y, yl, yh = agg(gnn_ltp, in_s, out_s)\n",
    "        ax.plot(\n",
    "            x, y, color=colors[\"gnn\"][i], linestyle=linestyles[\"gnn\"][i],marker=markers[\"gnn\"][i],linewidth=3\n",
    "        )\n",
    "        ax.fill_between(x, yl, yh, color=colors[\"gnn\"][i], alpha=0.3)\n",
    "        \n",
    "        x, y, yl, yh = agg(mle_ltp, in_s, out_s)\n",
    "        yerr = np.concatenate([np.expand_dims(y-yl,0), np.expand_dims(yh-y,0)], axis=0)\n",
    "        ax.errorbar(\n",
    "            x, \n",
    "            y, \n",
    "            yerr=yerr,\n",
    "            color=colors[\"mle\"][i], \n",
    "            linestyle=linestyles[\"mle\"][i], \n",
    "            marker=markers[\"mle\"][i], \n",
    "            alpha=0.3\n",
    "        )\n",
    "#         ax.plot(\n",
    "#             x, y, color=colors[\"mle\"][i], linestyle=linestyles[\"mle\"][i], marker=markers[\"mle\"][i], alpha=0.5\n",
    "#         )\n",
    "#         ax.fill_between(x, yl, yh, color=colors[\"mle\"][i], alpha=0.3)\n",
    "        \n",
    "        if x.min() > x_min:\n",
    "            x_min = x.min()\n",
    "        if x.max() < x_max:\n",
    "            x_max = x.max()\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    return ax\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "plot_ltp(exp, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynalearn_env",
   "language": "python",
   "name": "dynalearn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
